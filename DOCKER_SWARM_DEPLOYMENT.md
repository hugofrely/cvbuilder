# ğŸ³ Guide de DÃ©ploiement Docker Swarm

Ce guide explique comment dÃ©ployer CVBuilder sur Docker Swarm avec Google Cloud Storage.

## ğŸ“‹ PrÃ©requis

- Docker Swarm initialisÃ©
- Traefik configurÃ© sur le rÃ©seau `traefik_public`
- AccÃ¨s Ã  un registry Docker (registry.frely.fr)
- Compte Google Cloud avec bucket GCS configurÃ©
- Projet Supabase configurÃ©
- Compte Stripe configurÃ©

## ğŸ”§ Configuration des Credentials GCS

### ProblÃ¨me: Fichiers de Credentials

Docker Swarm ne permet pas de monter facilement des fichiers de credentials. La solution est de passer les credentials GCS en tant que **variable d'environnement JSON**.

### Solution: GCS_CREDENTIALS_JSON

Le backend a Ã©tÃ© modifiÃ© pour supporter deux mÃ©thodes:

1. **DÃ©veloppement local**: Utiliser `GCS_CREDENTIALS_PATH` (chemin vers le fichier JSON)
2. **Docker Swarm/Production**: Utiliser `GCS_CREDENTIALS_JSON` (JSON string sur une seule ligne)

### Ã‰tapes pour Convertir les Credentials

#### MÃ©thode 1: Script Automatique (RecommandÃ©)

```bash
# Utilisez le script fourni
./scripts/convert-gcs-credentials.sh /path/to/your/gcs-credentials.json
```

Cela affichera quelque chose comme:
```
GCS_CREDENTIALS_JSON={"type":"service_account","project_id":"cvbuilder-476609",...}
```

Copiez cette ligne dans votre fichier `.env.swarm`.

#### MÃ©thode 2: Manuelle

```bash
# Installez jq si nÃ©cessaire
brew install jq  # macOS
# ou
sudo apt-get install jq  # Ubuntu/Debian

# Convertir le JSON en une seule ligne
cat /path/to/gcs-credentials.json | jq -c

# Copier le rÃ©sultat dans .env.swarm comme:
# GCS_CREDENTIALS_JSON={"type":"service_account",...}
```

## ğŸš€ DÃ©ploiement

### 1. CrÃ©er le Fichier d'Environnement

```bash
# Copier le template
cp .env.swarm.example .env.swarm

# Ã‰diter avec vos valeurs
nano .env.swarm
```

### 2. Remplir les Variables Obligatoires

Dans [.env.swarm](.env.swarm):

```bash
# Database
DB_PASSWORD=votre_mot_de_passe_postgres_securise

# Django
SECRET_KEY=votre_cle_secrete_django
DEBUG=False

# Supabase
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_ANON_KEY=eyJhbGc...
SUPABASE_SERVICE_KEY=eyJhbGc...
SUPABASE_JWT_SECRET=votre-jwt-secret

# Google Cloud Storage
USE_GCS=True
GCS_BUCKET_NAME=cvbuilder-images
GCS_PROJECT_ID=cvbuilder-476609
GCS_CREDENTIALS_JSON={"type":"service_account",...}

# Stripe
STRIPE_SECRET_KEY=sk_live_...
STRIPE_PUBLISHABLE_KEY=pk_live_...
STRIPE_WEBHOOK_SECRET=whsec_...
STRIPE_SINGLE_CV_PRICE_ID=price_...
STRIPE_LIFETIME_PREMIUM_PRICE_ID=price_...
```

### 3. Build et Push des Images

```bash
# Backend
docker build -t registry.frely.fr/cvbuilder-backend:latest ./backend
docker push registry.frely.fr/cvbuilder-backend:latest

# Frontend
docker build -t registry.frely.fr/cvbuilder-frontend:latest ./frontend
docker push registry.frely.fr/cvbuilder-frontend:latest
```

### 4. DÃ©ployer le Stack

```bash
# Charger les variables d'environnement
export $(cat .env.swarm | xargs)

# DÃ©ployer sur Swarm
docker stack deploy -c docker-compose.swarm.yml cvbuilder
```

### 5. VÃ©rifier le DÃ©ploiement

```bash
# Voir les services
docker stack services cvbuilder

# Voir les logs du backend
docker service logs -f cvbuilder_backend

# Voir les logs du frontend
docker service logs -f cvbuilder_frontend

# Voir les logs de Celery
docker service logs -f cvbuilder_celery
```

## ğŸ” VÃ©rifications Post-DÃ©ploiement

### 1. Backend API

```bash
curl https://api.bidly.fr/api/health/
```

Devrait retourner 200 OK.

### 2. Frontend

```bash
curl https://bidly.fr
```

Devrait retourner la page HTML.

### 3. GCS Upload Test

Testez l'upload d'une image de CV depuis l'interface pour vÃ©rifier que GCS fonctionne.

### 4. Supabase Auth

Testez la connexion via:
- Email/Password
- Google OAuth
- LinkedIn OAuth

## ğŸ› DÃ©pannage

### Erreur: "Failed to parse GCS_CREDENTIALS_JSON"

**Cause**: Le JSON n'est pas correctement formatÃ© ou Ã©chappÃ©.

**Solution**:
1. VÃ©rifiez que le JSON est valide: `echo "$GCS_CREDENTIALS_JSON" | jq`
2. Assurez-vous qu'il n'y a pas d'espaces avant/aprÃ¨s le `=`
3. Pas de guillemets autour de la valeur dans `.env.swarm`

**Bon**:
```bash
GCS_CREDENTIALS_JSON={"type":"service_account",...}
```

**Mauvais**:
```bash
GCS_CREDENTIALS_JSON = {"type":"service_account",...}  # Espaces autour du =
GCS_CREDENTIALS_JSON="{"type":"service_account",...}"  # Guillemets externes
```

### Erreur: "Google Cloud Storage authentication failed"

**VÃ©rifications**:
1. Le bucket GCS existe
2. Le service account a les permissions nÃ©cessaires (`Storage Object Admin`)
3. Le `GCS_PROJECT_ID` est correct
4. Le JSON credentials contient bien la `private_key`

### Erreur: "Invalid Supabase token"

**VÃ©rifications**:
1. `SUPABASE_JWT_SECRET` est correct (Dashboard > Settings > API > JWT Secret)
2. `SUPABASE_URL` pointe vers le bon projet
3. Les tokens ne sont pas expirÃ©s

### Les Images Docker ne se Mettent pas Ã  Jour

```bash
# Forcer le pull des nouvelles images
docker service update --force cvbuilder_backend
docker service update --force cvbuilder_frontend
```

## ğŸ“Š Architecture de Production

```
Internet
   â”‚
   â–¼
Traefik (HTTPS)
   â”‚
   â”œâ”€â–¶ Frontend (bidly.fr) â”€â”€â”€â”€â”€â”
   â”‚                             â”‚
   â””â”€â–¶ Backend (api.bidly.fr) â”€â”€â”¤
                                 â”‚
                                 â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  PostgreSQL   â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚     Redis     â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Celery Workerâ”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Google Cloud â”‚
                         â”‚    Storage    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Supabase    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Mise Ã  Jour de l'Application

### Rolling Update (Zero Downtime)

```bash
# 1. Build et push les nouvelles images
docker build -t registry.frely.fr/cvbuilder-backend:latest ./backend
docker push registry.frely.fr/cvbuilder-backend:latest

docker build -t registry.frely.fr/cvbuilder-frontend:latest ./frontend
docker push registry.frely.fr/cvbuilder-frontend:latest

# 2. Mettre Ã  jour le stack
export $(cat .env.swarm | xargs)
docker stack deploy -c docker-compose.swarm.yml cvbuilder

# Les services se mettront Ã  jour automatiquement avec:
# - parallelism: 1 (un container Ã  la fois)
# - order: start-first (dÃ©marrer le nouveau avant d'arrÃªter l'ancien)
```

## ğŸ“ Notes Importantes

### SÃ©curitÃ©

1. **Ne jamais commit** `.env.swarm` dans Git
2. **Rotation** rÃ©guliÃ¨re des secrets (DB_PASSWORD, SECRET_KEY, etc.)
3. **Audit** des accÃ¨s GCS service account
4. **Monitoring** des logs pour dÃ©tecter les accÃ¨s non autorisÃ©s

### Performance

1. **Scaling**: Ajustez `replicas` selon la charge
2. **Redis**: Pour scaling horizontal, considÃ©rez Redis Cluster
3. **PostgreSQL**: Envisagez des rÃ©plicas read-only pour la lecture
4. **GCS**: Activez le CDN si beaucoup de lectures d'images

### Backup

1. **PostgreSQL**: Backup rÃ©gulier avec `pg_dump`
2. **GCS**: Versionning activÃ© sur le bucket
3. **Secrets**: Backup sÃ©curisÃ© de `.env.swarm`

## ğŸ†˜ Support

**ProblÃ¨me de dÃ©ploiement ?**
1. VÃ©rifiez les logs: `docker service logs cvbuilder_backend`
2. VÃ©rifiez la configuration: `docker service inspect cvbuilder_backend`
3. Consultez [TROUBLESHOOTING.md](./TROUBLESHOOTING.md)

---

**DerniÃ¨re mise Ã  jour:** 2025-11-02
